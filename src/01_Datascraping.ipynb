{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping gempundit.com\n",
    "We obtain our data by scraping the website gempundit.com. The store offers a variety of gemstones and for each product there are multiple images from different angles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_13372\\4088295962.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\david\\miniconda3\\envs\\gemstone\\lib\\site-packages\\gevent\\hub.py:161: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "#import requests\n",
    "import grequests\n",
    "import shutil\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "import concurrent.futures as cf\n",
    "from tqdm import tqdm\n",
    "from random import randint, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMSTONES_CATEGORY_URL = 'https://www.gempundit.com/gemstones'\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "session = grequests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "executor = cf.ThreadPoolExecutor(max_workers=12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the links for all of the type of gemstone from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AsyncRequest' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msuccesfully collected all gem links\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m gem_links\n\u001b[1;32m---> 18\u001b[0m gem_links \u001b[39m=\u001b[39m get_all_gem_links_website(GEMSTONES_CATEGORY_URL)\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mget_all_gem_links_website\u001b[1;34m(ALL_GEMS_URL)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_gem_links_website\u001b[39m(ALL_GEMS_URL):\n\u001b[1;32m----> 2\u001b[0m     html \u001b[39m=\u001b[39m grequests\u001b[39m.\u001b[39;49mget(ALL_GEMS_URL, headers\u001b[39m=\u001b[39;49mHEADERS)\u001b[39m.\u001b[39;49mtext\n\u001b[0;32m      3\u001b[0m     soup \u001b[39m=\u001b[39m bs(html, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msuccesfully loaded page\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AsyncRequest' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "def get_all_gem_links_website(ALL_GEMS_URL):\n",
    "    request = grequests.get(ALL_GEMS_URL, headers=HEADERS)\n",
    "    response = grequests.map([request])\n",
    "    html = response[0].text\n",
    "    soup = bs(html, 'html.parser')\n",
    "    print('succesfully loaded page')\n",
    "    gem_table = soup.find('div', {'class': 'container'})\n",
    "    print('succesfully found gem table, now collecting links')\n",
    "    gem_aClass = gem_table.find_all('a', {'data-category': 'gemstones'})\n",
    "    gem_links = {}\n",
    "    for gem in gem_aClass:\n",
    "        link = gem.get('href')\n",
    "        title = gem.get('title')\n",
    "        print(title)\n",
    "        # add the link to the dictionary\n",
    "        gem_links[title] = link\n",
    "    print('succesfully collected all gem links')\n",
    "    return gem_links\n",
    "\n",
    "gem_links = get_all_gem_links_website(GEMSTONES_CATEGORY_URL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we collect the links to all of the product pages for each gemstone category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gem_pages(gem_links):    \n",
    "    print('getting all gem pages')\n",
    "    gem_page_links = {}\n",
    "    for gem in gem_links:\n",
    "        print('\\n', gem)\n",
    "        try:\n",
    "            number_of_pages = int(bs(grequests.get(gem_links[gem]+'/page/1000', headers=HEADERS).text, 'html.parser').find('li', {'class': 'current'}).text)\n",
    "        except:\n",
    "            number_of_pages = 1\n",
    "        print('')\n",
    "        print(gem, number_of_pages)\n",
    "        gem_page_links[gem] = []\n",
    "        for page_no in range(1, number_of_pages+1):\n",
    "            gem_page_links[gem].append(gem_links[gem]+'/page/'+str(page_no))\n",
    "            #print(page_no, ', ', end='')\n",
    "    print('-'*50)\n",
    "    print('succesfully collected links')\n",
    "    return gem_page_links\n",
    "all_pages = get_all_gem_pages(gem_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later use we will save the dictionary with all the gemstone page links as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gem_page_links(gem_page_links):\n",
    "    with open(\"../dat/page_links/gem_page_links.json\", \"w\") as outfile:\n",
    "        json.dump(gem_page_links, outfile)\n",
    "save_gem_page_links(all_pages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reloading gemstone page links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gem_page_links():\n",
    "    with open(\"../dat/page_links/gem_page_links.json\", \"r\") as outfile:\n",
    "        gem_page_links = json.load(outfile)\n",
    "    return gem_page_links\n",
    "all_pages = load_gem_page_links()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining all the links to the gemstone pages, we will extract the links to each product.\n",
    "\n",
    "Because of the access and speed limits, we will use multiple threads to collect the links.\n",
    "\n",
    "The webpage has a rate limit so after each collected links, we will do a random sleep between 0.1 and 5 seconds.\n",
    "If we don't do this, the website will block our reqests.\n",
    "\n",
    "The collected product links will be saves in the directory `dat/product_links`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to collect all product links\n",
      "skipping Cats Eye\n",
      "skipping Hessonite (Gomed)\n",
      "skipping Pearl (Moti)\n",
      "skipping Red Coral (Moonga)\n",
      "skipping White Sapphire\n",
      "skipping Yellow Sapphire - Pukhraj\n",
      "skipping Amethyst\n",
      "skipping Fire Opal\n",
      "skipping Garnet\n",
      "skipping Citrine (Sunela)\n",
      "skipping Navratna\n",
      "skipping Peridot\n",
      "skipping Iolite (Neeli)\n",
      "skipping Turquoise\n",
      "skipping White Coral\n",
      "skipping Pitambari Neelam\n",
      "skipping Zircon\n",
      "skipping Yellow Topaz\n",
      "skipping Colombian Emerald\n",
      "skipping Cornflower Blue Sapphire\n",
      "skipping Burmese Ruby\n",
      "skipping Alexandrite\n",
      "skipping Kashmir Blue Sapphire\n",
      "skipping Padparadscha Sapphire\n",
      "skipping No Oil Emerald\n",
      "skipping Pigeon Blood Ruby\n",
      "skipping Panjshir Emerald\n",
      "skipping Paraiba Tourmaline\n",
      "skipping Pink Sapphire\n",
      "skipping Royal Blue Sapphire\n",
      "skipping Aquamarine\n",
      "skipping Blue Topaz\n",
      "skipping Kyanite\n",
      "skipping Lapis Lazuli\n",
      "skipping Ametrine\n",
      "skipping Tanzanite\n",
      "skipping Amber\n",
      "skipping Moldavite\n",
      "skipping Moonstone\n",
      "skipping Star Ruby\n",
      "skipping Spinel\n",
      "skipping Tourmaline\n",
      "skipping Blue Zircon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [16:38<00:00, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully collected all product links\n",
      "succesfully collected all product links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_individual_gem_links(data):\n",
    "    gem = data[0]\n",
    "    links = data[1]\n",
    "\n",
    "    if os.path.exists('../dat/product_links/' + gem + '.csv'):\n",
    "        print('skipping', gem)\n",
    "        return\n",
    "    gem_product_links = []\n",
    "    # check if csv file exists\n",
    "    for page in links:\n",
    "        html = grequests.get(page, headers=HEADERS).text\n",
    "        soup = bs(html, 'html.parser')\n",
    "        gem_product_pages = soup.find_all('a', {'class': 'product-image dataimage'})\n",
    "        gem_product_links.extend([page.get('href') for page in gem_product_pages])\n",
    "        # sleep for a random time to avoid being blocked\n",
    "        sleep(random()*2)\n",
    "        if random() < 0.1:\n",
    "            sleep(randint(1, 5))\n",
    "    pd.DataFrame(gem_product_links, columns=[gem]).to_csv('../dat/product_links/' + gem + '.csv')\n",
    "    sleep(10)\n",
    "    return 1\n",
    "def get_gem_product_links(gem_page_links):\n",
    "    futures = [executor.submit(get_individual_gem_links, [gem, gem_page_links[gem]]) for gem in gem_page_links]\n",
    "    with tqdm(total=len(futures)) as pbar:\n",
    "        for future in cf.as_completed(futures):\n",
    "            result = future.result()\n",
    "            pbar.update()\n",
    "    print('succesfully collected all product links')\n",
    "    \n",
    "print('starting to collect all product links')\n",
    "get_gem_product_links(all_pages)\n",
    "print('succesfully collected all product links')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each product page, we will scrape the image links contained within the page.\n",
    "This is again done using multiple threads to speed up the process.\n",
    "\n",
    "The collected image links will be saved as a CSV file in the `dat/image_links/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_links(data):\n",
    "    gem = data[0]\n",
    "    links = data[1]\n",
    "\n",
    "    def extract_img_links(response):\n",
    "        soup = bs(response.content, 'html.parser')\n",
    "        img_links = [img['src'].split('?')[0] for div in soup.find_all(\"div\", class_=\"item product_thumb_forHeight\") \n",
    "                     for img in div.find_all('img')\n",
    "                     if 'certi' not in img['src'] and 'hand' not in img['src']]\n",
    "        return img_links\n",
    "\n",
    "    # Build asynchronous requests using grequests\n",
    "    requests = [grequests.get(link, headers=HEADERS, session=session) for link in links]\n",
    "\n",
    "    # Send requests asynchronously\n",
    "    responses = grequests.imap(requests, size=16)  # Adjust concurrency with 'size' \n",
    "\n",
    "    gem_img_links = []\n",
    "    futures = []\n",
    "\n",
    "    with tqdm(total=len(links)) as pbar:\n",
    "        for response in responses:\n",
    "            future = executor.submit(extract_img_links, response)\n",
    "            futures.append(future)\n",
    "            pbar.update()\n",
    "    \n",
    "    print('waiting for all threads to complete')\n",
    "\n",
    "    for future in cf.as_completed(futures):\n",
    "        gem_img_links.extend(future.result())\n",
    "    # Save results\n",
    "    pd.DataFrame(gem_img_links, columns=[gem]).to_csv(f'../dat/image_links/{gem}.csv')\n",
    "\n",
    "# def read_gem_product_links():\n",
    "#     gem_product_links = {}\n",
    "#     for file in os.listdir('../dat/product_links'):\n",
    "#         data = pd.read_csv('../dat/product_links/' + file, index_col=0)\n",
    "#         gem = data.columns[0]\n",
    "#         gem_product_links[gem] = data[gem].tolist()\n",
    "#     return gem_product_links\n",
    "\n",
    "def get_all_gem_image_links():\n",
    "    for file in os.listdir('../dat/product_links/'):\n",
    "        if os.path.exists('../dat/image_links/' + file):\n",
    "            print('skipping', gem)\n",
    "            continue\n",
    "        data = pd.read_csv('../dat/product_links/' + file, index_col=0)\n",
    "        gem = data.columns[0]\n",
    "        links = data[gem].tolist()\n",
    "\n",
    "        print('getting image links for', gem)\n",
    "        get_img_links([gem, links])\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup as bs\n",
    "# import grequests\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "\n",
    "def get_img_links(data):\n",
    "    gem, links = data\n",
    "\n",
    "    def extract_img_links(response):\n",
    "        if response.status_code == 200:\n",
    "            soup = bs(response.content, 'lxml')  # Use 'lxml' for faster parsing\n",
    "            img_links = [img['src'].split('?')[0] for div in soup.find_all(\"div\", class_=\"item product_thumb_forHeight\")\n",
    "                         for img in div.find_all('img')\n",
    "                         if 'certi' not in img['src'] and 'hand' not in img['src']]\n",
    "            return img_links\n",
    "        else:\n",
    "            return []  # Return an empty list in case of HTTP errors\n",
    "\n",
    "    # # Use a session for connection pooling\n",
    "    # requests = (grequests.get(link, headers=HEADERS) for link in links)\n",
    "\n",
    "    # # Send requests asynchronously and adjust concurrency with 'size'\n",
    "    # responses = grequests.imap(requests, size=24)\n",
    "    responses = []\n",
    "    futures = [executor.submit(requests.get, link, headers=HEADERS) for link in links]\n",
    "    with tqdm(total=len(links)) as pbar:\n",
    "        for future in cf.as_completed(futures):\n",
    "            response = future.result()\n",
    "            responses.append(response)\n",
    "            pbar.update()\n",
    "\n",
    "    gem_img_links = []\n",
    "\n",
    "    future_to_response = {executor.submit(extract_img_links, response): response for response in responses}\n",
    "\n",
    "    with tqdm(total=len(links)) as pbar:\n",
    "        for future in cf.as_completed(future_to_response):\n",
    "            gem_img_links.extend(future.result())\n",
    "            pbar.update()\n",
    "\n",
    "    # Save results\n",
    "    pd.DataFrame(gem_img_links, columns=[gem]).to_csv(f'../dat/image_links/{gem}.csv')\n",
    "\n",
    "def read_gem_product_links():\n",
    "    gem_product_links = {}\n",
    "    for file in os.listdir('../dat/product_links'):\n",
    "        data = pd.read_csv(f'../dat/product_links/{file}', index_col=0)\n",
    "        gem = data.columns[0]\n",
    "        gem_product_links[gem] = data[gem].tolist()\n",
    "    return gem_product_links\n",
    "\n",
    "def get_all_gem_image_links():\n",
    "    for file in os.listdir('../dat/product_links/'):\n",
    "        if os.path.exists(f'../dat/image_links/{file}'):\n",
    "            print('skipping', file.split('.')[0])  # Corrected to display the gem name being skipped\n",
    "            continue\n",
    "        data = pd.read_csv(f'../dat/product_links/{file}', index_col=0)\n",
    "        gem = data.columns[0]\n",
    "        links = data[gem].tolist()\n",
    "\n",
    "        print('getting image links for', gem)\n",
    "        get_img_links([gem, links])\n",
    "        print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping Alexandrite\n",
      "skipping Amber\n",
      "skipping Amethyst\n",
      "skipping Ametrine\n",
      "skipping Aquamarine\n",
      "skipping Blue Sapphire (Neelam)\n",
      "skipping Blue Topaz\n",
      "skipping Blue Zircon\n",
      "skipping Burmese Ruby\n",
      "skipping Cats Eye\n",
      "skipping Citrine (Sunela)\n",
      "skipping Colombian Emerald\n",
      "skipping Cornflower Blue Sapphire\n",
      "skipping Emerald (Panna)\n",
      "skipping Fire Opal\n",
      "skipping Garnet\n",
      "skipping Hessonite (Gomed)\n",
      "skipping Iolite (Neeli)\n",
      "skipping Kashmir Blue Sapphire\n",
      "skipping Kyanite\n",
      "skipping Lapis Lazuli\n",
      "skipping Moldavite\n",
      "skipping Moonstone\n",
      "skipping Navratna\n",
      "skipping No Oil Emerald\n",
      "skipping Opal\n",
      "skipping Padparadscha Sapphire\n",
      "skipping Panjshir Emerald\n",
      "skipping Paraiba Tourmaline\n",
      "skipping Pearl (Moti)\n",
      "skipping Peridot\n",
      "skipping Pigeon Blood Ruby\n",
      "skipping Pink Sapphire\n",
      "skipping Pitambari Neelam\n",
      "skipping Red Coral (Moonga)\n",
      "skipping Royal Blue Sapphire\n",
      "skipping Ruby (Manik)\n",
      "skipping Spinel\n",
      "skipping Star Ruby\n",
      "skipping Tanzanite\n",
      "skipping Tourmaline\n",
      "skipping Turquoise\n",
      "skipping White Coral\n",
      "getting image links for White Sapphire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [05:57<00:00,  2.78it/s]  \n",
      "100%|██████████| 993/993 [07:29<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "getting image links for Yellow Sapphire - Pukhraj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1999/1999 [16:23<00:00,  2.03it/s] \n",
      "100%|██████████| 1999/1999 [25:53<00:00,  1.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "getting image links for Yellow Topaz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [02:21<00:00,  1.11s/it]\n",
      "100%|██████████| 127/127 [01:41<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "getting image links for Zircon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1095/1095 [03:54<00:00,  4.67it/s]\n",
      "100%|██████████| 1095/1095 [01:39<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\gemstone\\lib\\site-packages\\gevent\\hub.py:161: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "get_all_gem_image_links()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wo download all the collected images to the `dat/images` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [1:35:35<00:00, 122.04s/it]\n",
      "c:\\Users\\david\\miniconda3\\envs\\gemstone\\lib\\site-packages\\gevent\\hub.py:161: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "def save_image(gem, response):\n",
    "    filename = response.url.split('/p')[-1].split('/')[1].split('?')[0]\n",
    "\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')  # Convert to RGB if necessary\n",
    "    img.save(os.path.join(img_path, gem, filename + '.jpg'), format='JPEG')\n",
    "\n",
    "# Asynchronous image downloads\n",
    "def process_gem(gem, links):\n",
    "    reqs = (grequests.get(link, stream=True, headers=HEADERS, session=session) for link in links)\n",
    "    responses = grequests.imap(reqs, size=8)  # Adjust pool size\n",
    "\n",
    "    for response in responses:\n",
    "        if response:  # Skip failures\n",
    "            save_image(gem, response)\n",
    "\n",
    "def process_file(file):\n",
    "    data = pd.read_csv(file, index_col=0)\n",
    "    gem = data.columns[0]\n",
    "    links = data[gem].tolist()\n",
    "    os.makedirs(img_path + gem, exist_ok=True)\n",
    "    process_gem(gem, links)\n",
    "\n",
    "link_path = '../dat/image_links'\n",
    "img_path = '../dat/images/'\n",
    "\n",
    "executor = cf.ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "futures = [executor.submit(process_file, os.path.join(link_path, file)) for file in os.listdir(link_path)]\n",
    "with tqdm(total=len(futures)) as pbar:\n",
    "    for future in cf.as_completed(futures):\n",
    "        future.result()\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f762acd087eee1e20edab5fbefd8c93a224f39ec9e7e44d927d5a8eeabcf7075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
