{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models\n",
    "On the previously constructed dataset, we will train the following classificaiton models:\n",
    "- VGG16\n",
    "- MobileNet\n",
    "- ResNet50\n",
    "\n",
    "Further we will define our own model and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, MobileNet, ResNet50  # Using ResNet50\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141949 images belonging to 170 classes.\n",
      "Found 35410 images belonging to 170 classes.\n",
      "Epoch 1/10\n",
      " 537/4436 [==>...........................] - ETA: 22:27 - loss: 3.7658 - accuracy: 0.1300 - top_3_accuracy: 0.3023 - top_5_accuracy: 0.4111"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\PIL\\Image.py\", line 3309, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[categorical_crossentropy/softmax_cross_entropy_with_logits/Shape_2/_10]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\PIL\\Image.py\", line 3309, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_17649]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 82\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     results[model_name] \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Save model parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\PIL\\Image.py\", line 3309, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[categorical_crossentropy/softmax_cross_entropy_with_logits/Shape_2/_10]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\nTraceback (most recent call last):\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"c:\\Users\\david\\miniforge3\\envs\\cuda\\lib\\site-packages\\PIL\\Image.py\", line 3309, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000001D5ED03BDD0>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_17649]"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "#data_dir = \"../dat/images_augmented_cropped\" \n",
    "data_dir = \"../dat/gempundit_all\"\n",
    "target_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "validation_split = 0.2  # Percentage of data to use for validation\n",
    "\n",
    "# Data Generator with Splitting\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)\n",
    "\n",
    "# Load data with the split\n",
    "train_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training' \n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation' \n",
    ")\n",
    "\n",
    "# Model Creation with Pre-trained Weights\n",
    "def create_model(model_type):\n",
    "    if model_type == \"VGG16\":\n",
    "        base_model = VGG16(include_top=False, weights='imagenet', input_shape=target_size + (3,))\n",
    "    elif model_type == \"MobileNet\":\n",
    "        base_model = MobileNet(include_top=False, weights='imagenet', input_shape=target_size + (3,))\n",
    "    elif model_type == \"ResNet50\":\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet', input_shape=target_size + (3,))\n",
    "    elif model_type == \"OwnModel\":\n",
    "        kernel_size =  3  # Example value\n",
    "        max_pool =  2  # Example value\n",
    "        base_model = Sequential([\n",
    "            # First layer\n",
    "            Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', input_shape=target_size + (3,)),\n",
    "            MaxPooling2D((max_pool, max_pool)),\n",
    "            # Second layer\n",
    "            Conv2D(64, (kernel_size, kernel_size), activation='relu', padding='same'),\n",
    "            MaxPooling2D((max_pool, max_pool)),\n",
    "            # Third layer\n",
    "            Conv2D(128, (kernel_size, kernel_size), activation='relu', padding='same'),\n",
    "            MaxPooling2D((max_pool, max_pool)),\n",
    "            # Fourth layer\n",
    "            Conv2D(128, (kernel_size, kernel_size), activation='relu', padding='same'),\n",
    "            AveragePooling2D(pool_size=(2,  2), strides=(2,  2)),\n",
    "            # Fifth layer\n",
    "            Conv2D(128, (kernel_size, kernel_size), activation='relu', padding='same'),\n",
    "            MaxPooling2D((max_pool, max_pool)),\n",
    "])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type\")\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(train_data.num_classes, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top_3_accuracy\", dtype=None), tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top_5_accuracy\", dtype=None)])\n",
    "    return model\n",
    "\n",
    "# Training and Evaluation\n",
    "models = {\n",
    "    \"VGG16\": create_model(\"VGG16\"),\n",
    "    \"MobileNet\": create_model(\"MobileNet\"),\n",
    "    \"ResNet50\": create_model(\"ResNet50\"),\n",
    "    \"OwnModel\": create_model(\"OwnModel\"),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    history = model.fit(train_data, epochs=num_epochs, validation_data=val_data)\n",
    "    results[model_name] = history.history\n",
    "\n",
    "    # Save model parameters\n",
    "    model.save(f\"../mod/{model_name}.h5\")\n",
    "    # Convert history to DataFrame\n",
    "    df = pd.DataFrame(history)\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(f\"../mod/{model_name}_history.csv\", index=False)\n",
    "\n",
    "print(\"Training and Evaluation Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f762acd087eee1e20edab5fbefd8c93a224f39ec9e7e44d927d5a8eeabcf7075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
